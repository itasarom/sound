{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "DATA_PATH = './data'\n",
    "join_path = lambda path: os.path.join(DATA_PATH, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(join_path('train_curated/*')) # именно в таком порядке будут идти все аудиозаписи\n",
    "\n",
    "train = pd.read_csv(join_path('train_curated.csv')).set_index('fname')\n",
    "\n",
    "cats = list(set(sum(list(train['labels'].str.split(',').values), [])))\n",
    "\n",
    "train['enc_labels'] = train['labels'].str.split(',').apply(lambda x: [int(label in x) for label in cats])\n",
    "\n",
    "targets = np.array(train.loc[[fp[-12:] for fp in filepaths], 'enc_labels'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import models\n",
    "import trainer\n",
    "import mclnn\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4464/4464 [07:14<00:00,  7.88it/s]\n",
      "100%|██████████| 506/506 [00:42<00:00, 11.93it/s]\n",
      "100%|██████████| 73/73 [00:08<00:00,  8.12it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class conf:\n",
    "    # Preprocessing settings\n",
    "    sampling_rate = 44100\n",
    "    duration = 2\n",
    "    hop_length = 347*duration # to make time steps 128\n",
    "#     hop_length = 694*duration\n",
    "    fmin = 20\n",
    "    fmax = sampling_rate // 2\n",
    "    n_mels = 128\n",
    "    n_fft = n_mels * 20\n",
    "    samples = sampling_rate * duration\n",
    "    trim_long_data = False\n",
    "    \n",
    "conf.columns, conf.column_encoder = utils.read_columns()\n",
    "\n",
    "train_x, train_y, _ = utils.read_dataset_split(\"./data/train_curated.csv\", \"./splits/split/train\", conf, lambda s: s)\n",
    "test_x, test_y, _ = utils.read_dataset_split(\"./data/train_curated.csv\", \"./splits/split/val\", conf, lambda s: s)\n",
    "\n",
    "all_rooms_meta, all_rooms = utils.read_filters(\"./filters/\", conf, lambda s: s)\n",
    "\n",
    "test_x = list(map(lambda s: utils.trim_and_mel(conf, s), test_x))\n",
    "\n",
    "train_dataset = trainer.SoundAugDataset(train_x, train_y, \n",
    "                                        transform = lambda s: utils.audio_to_melspectrogram(conf, s),\n",
    "                                        room_filters=all_rooms[:3], \n",
    "                                        params={\n",
    "                                                    \"max_size\":len(train_x),\n",
    "                                                    \"max_n_mixed\":2,\n",
    "#                                                     \"change_pitch\":0.1,\n",
    "#                                                     \"change_pitch_max\":1,\n",
    "                                                    \"add_echo\":0.5,\n",
    "#                                                     \"harmonic_percussive\":0.1,\n",
    "#                                                     \"noise_magnitude\":0.00005\n",
    "                                               },\n",
    "                                        config=conf,\n",
    "                                        seed=42)\n",
    "test_dataset = trainer.SoundDataset(test_x, test_y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_coll = trainer.AugmentationCollator(conf, None, True)\n",
    "train_dl = DataLoader(train_dataset, batch_size=64, collate_fn=aug_coll, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dl = DataLoader(test_dataset, batch_size=64, collate_fn=trainer.collate_fn_2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mclnn\n",
    "base = nn.Sequential(\n",
    "    mclnn.CLNNModule(128, 256, 4, dilation=1),\n",
    "    nn.LeakyReLU(),\n",
    "    mclnn.BatchNorm(256),\n",
    "    mclnn.CLNNModule(256, 256, 4, dilation=1),\n",
    "    nn.LeakyReLU(),\n",
    "    mclnn.TemporalPool(2),\n",
    "    mclnn.BatchNorm(256),\n",
    "    mclnn.CLNNModule(256, 256, 4, dilation=1),\n",
    "    nn.LeakyReLU(),\n",
    "    mclnn.TemporalPool(2),\n",
    "    mclnn.CLNNModule(256, 256, 4),\n",
    "    nn.LeakyReLU(),\n",
    "    mclnn.TemporalPool(4),\n",
    "    mclnn.BatchNorm(256),\n",
    "    mclnn.Flatten(),\n",
    "    nn.Linear(256*8, 1024),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(1024, 80)\n",
    ")\n",
    "\n",
    "class W(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = input.squeeze(1)\n",
    "        return self.model(input)\n",
    "    \n",
    "model = W(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-multilearn \n",
    "# from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "# train_X, train_y, test_X, test_y = iterative_train_test_split(X=data, y=targets, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = TensorDataset(torch.tensor(train_X).unsqueeze(1), torch.tensor(train_y).float())\n",
    "# val_ds = TensorDataset(torch.tensor(test_X).unsqueeze(1), torch.tensor(test_y).float())\n",
    "\n",
    "# train_dl = DataLoader(train_ds, batch_size=64)\n",
    "# val_dl = DataLoader(val_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = Model(num_classes=80)\n",
    "logdir = join_path('logdir')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n",
      "WARNING:root:Debug message: /opt/caffe2/build/caffe2/python/caffe2_pybind11_state_gpu.so: undefined symbol: _ZN5fLI6438FLAGS_caffe2_max_keep_on_shrink_memoryE\n",
      "CRITICAL:root:Cannot load caffe2.python. Error: /opt/caffe2/build/caffe2/python/caffe2_pybind11_state.so: undefined symbol: _ZN5fLI6438FLAGS_caffe2_max_keep_on_shrink_memoryE\n"
     ]
    }
   ],
   "source": [
    "from kirill.flame import Trainer # мой небольшой пайплайн для тренировки сеток\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, device, logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 epoch. train: 0.00198. val: 0.00121. time: 76.167s.\n",
      "  2 epoch. train: 0.00159. val: 0.00121. time: 151.688s.\n",
      "  3 epoch. train: 0.00149. val: 0.00121. time: 227.603s.\n",
      "  4 epoch. train: 0.00137. val: 0.00124. time: 302.526s.\n",
      "  5 epoch. train: 0.00124. val: 0.00125. time: 379.171s.\n",
      "  6 epoch. train: 0.00109. val: 0.00138. time: 455.731s.\n",
      "  7 epoch. train: 0.00091. val: 0.00147. time: 531.790s.\n",
      "  8 epoch. train: 0.00076. val: 0.00176. time: 607.959s.\n",
      "  9 epoch. train: 0.00068. val: 0.00171. time: 684.863s.\n",
      " 10 epoch. train: 0.00065. val: 0.00210. time: 760.980s.\n",
      " 11 epoch. train: 0.00062. val: 0.00243. time: 838.014s.\n",
      " 12 epoch. train: 0.00061. val: 0.00236. time: 914.303s.\n",
      " 13 epoch. train: 0.00062. val: 0.00241. time: 993.766s.\n",
      " 14 epoch. train: 0.00056. val: 0.00261. time: 1074.840s.\n",
      " 15 epoch. train: 0.00045. val: 0.00267. time: 1155.898s.\n",
      " 16 epoch. train: 0.00037. val: 0.00261. time: 1235.745s.\n",
      " 17 epoch. train: 0.00029. val: 0.00253. time: 1315.813s.\n",
      " 18 epoch. train: 0.00023. val: 0.00269. time: 1391.574s.\n",
      " 19 epoch. train: 0.00020. val: 0.00286. time: 1468.472s.\n",
      " 20 epoch. train: 0.00016. val: 0.00275. time: 1555.544s.\n",
      " 21 epoch. train: 0.00013. val: 0.00314. time: 1646.324s.\n",
      " 22 epoch. train: 0.00011. val: 0.00317. time: 1738.850s.\n",
      " 23 epoch. train: 0.00009. val: 0.00340. time: 1830.193s.\n",
      " 24 epoch. train: 0.00007. val: 0.00331. time: 1921.386s.\n",
      " 25 epoch. train: 0.00006. val: 0.00340. time: 2012.693s.\n",
      " 26 epoch. train: 0.00005. val: 0.00348. time: 2103.515s.\n",
      " 27 epoch. train: 0.00004. val: 0.00357. time: 2180.127s.\n",
      " 28 epoch. train: 0.00004. val: 0.00361. time: 2256.985s.\n",
      " 29 epoch. train: 0.00003. val: 0.00362. time: 2334.320s.\n",
      " 30 epoch. train: 0.00002. val: 0.00359. time: 2412.824s.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-079840ba28fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # пример запуска для минимизации логлосса\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# losses, best_loss, epoch_time = utils.train_model(trainer, train_dl, val_dl, val_y, scheduler,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/home/itasarom/projects/sound/kirill/flame.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, n_epochs, checkpoints, verbose, actions)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0maction_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{:3d} epoch. train: {:.5f}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/home/itasarom/projects/sound/kirill/flame.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, loader, verbose)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "# # пример запуска для минимизации логлосса\n",
    "trainer.train(train_dl, val_dl, n_epochs=240, verbose=True)\n",
    "\n",
    "\n",
    "# losses, best_loss, epoch_time = utils.train_model(trainer, train_dl, val_dl, val_y, scheduler,\n",
    "#                                             n_epochs=1000, gap=20, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.06763. Iter: 100%|██████████| 70/70 [00:14<00:00,  5.24it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.90it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32207662069576626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.05798. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.67it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 13.35it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166380930591757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.05236. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.22it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.11it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4582206474353202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.04700. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.20it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.24it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4928546655237012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.04262. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.63it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 13.09it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5295653557993734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.03912. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.20it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.19it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5703799406704296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.03511. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.16it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 11.98it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5884857284496896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.03391. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.12it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 11.95it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.613799956117646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.03119. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.15it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 11.86it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5996618968494476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.02637. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.57it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 13.34it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5988951360838559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.02486. Iter: 100%|██████████| 70/70 [00:14<00:00,  5.61it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 13.27it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646209654193764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.02322. Iter: 100%|██████████| 70/70 [00:14<00:00,  5.60it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 13.29it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6551752026880457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.02049. Iter: 100%|██████████| 70/70 [00:14<00:00,  5.46it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.92it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6473820956121759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.01926. Iter: 100%|██████████| 70/70 [00:14<00:00,  5.50it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.10it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6441005260998045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.01784. Iter: 100%|██████████| 70/70 [00:14<00:00,  5.59it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.99it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6626067061164259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.01505. Iter: 100%|██████████| 70/70 [00:14<00:00,  5.58it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.93it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6737623354909517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.01228. Iter: 100%|██████████| 70/70 [00:14<00:00,  5.56it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.99it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6784166777225116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.01107. Iter: 100%|██████████| 70/70 [00:14<00:00,  5.61it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.97it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6772803548081768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.01175. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.17it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.84it/s]\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6778412922729062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.01064. Iter: 100%|██████████| 70/70 [00:15<00:00,  5.19it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6585010786758971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from metrics import lwlrap_score\n",
    "\n",
    "# если хочется считать скор метрики оргов\n",
    "losses = []\n",
    "for i in range(20):\n",
    "    # делает один проход по даталоадеру\n",
    "    trainer.train_step(train_dl, verbose=True)\n",
    "    \n",
    "    # формируем предсказания\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for batch in tqdm.tqdm(val_dl):\n",
    "        batch = batch[0].to(device)\n",
    "        pred = model(batch)\n",
    "        preds.append(pred.cpu().detach().numpy())\n",
    "    preds = np.vstack(preds)\n",
    "    \n",
    "    # считаем скор метрики оргов\n",
    "    score = lwlrap_score(test_y, preds)\n",
    "    print(score)\n",
    "    \n",
    "    losses.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test inference\n",
    "\n",
    "with open(join_path('test_mels.pkl'), 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "    \n",
    "test_filepaths = glob.glob(join_path('test/*'))\n",
    "\n",
    "test_ds = TensorDataset(torch.tensor(test_data).unsqueeze(1))\n",
    "test_dl = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "for batch in tqdm.tqdm(test_dl):\n",
    "    batch = batch[0].to(device)\n",
    "    pred = model(batch)\n",
    "    preds.append(pred.cpu().detach().numpy())\n",
    "preds = np.vstack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(preds)\n",
    "sub.columns = [label for label in cats]\n",
    "sub['fname'] = [fp[-12:] for fp in test_filepaths]\n",
    "sub.to_csv(\"sub3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
